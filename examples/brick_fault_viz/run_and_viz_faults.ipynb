{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Brick Model Fault Detection & Visualization\n",
        "\n",
        "Run all Brick-mapped rules on AHU7 data, then **zoom in on fault events** to inspect them. This notebook sets up the next tutorial: **working with false positives**.\n",
        "\n",
        "## Workflow\n",
        "1. Load Brick TTL, resolve column map, run rules (same as `run_all_rules_brick.py`)\n",
        "2. Extract fault *events* (contiguous fault regions)\n",
        "3. Randomly sample events and zoom in with plots\n",
        "4. Inspect signals during fault windows — ready for false-positive analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Run Brick-driven fault detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Paths: run from project root, examples/, or examples/brick_fault_viz/\n",
        "cwd = Path(\".\").resolve()\n",
        "if (cwd / \"examples\" / \"brick_model.ttl\").exists():\n",
        "    EXAMPLES = cwd / \"examples\"\n",
        "    ROOT = cwd\n",
        "elif (cwd / \"brick_model.ttl\").exists():\n",
        "    EXAMPLES = cwd\n",
        "    ROOT = cwd.parent\n",
        "else:\n",
        "    EXAMPLES = cwd.parent  # notebook in examples/brick_fault_viz/\n",
        "    ROOT = EXAMPLES.parent\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT))\n",
        "\n",
        "from open_fdd.engine.brick_resolver import resolve_from_ttl, get_equipment_types_from_ttl\n",
        "from open_fdd.engine.runner import RuleRunner, load_rules_from_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _filter_rules_by_equipment(rules, equipment_types):\n",
        "    if not equipment_types:\n",
        "        return rules\n",
        "    return [r for r in rules if not r.get(\"equipment_type\") or any(et in equipment_types for et in r.get(\"equipment_type\", []))]\n",
        "\n",
        "def _add_synthetic_columns(df, column_map):\n",
        "    df = df.copy()\n",
        "    for brick_key, csv_col in column_map.items():\n",
        "        if csv_col not in df.columns and (\"Setpoint\" in brick_key or \"setpoint\" in brick_key.lower()):\n",
        "            df[csv_col] = 0.5\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ttl_path = EXAMPLES / \"brick_model.ttl\"\n",
        "rules_dir = EXAMPLES / \"my_rules\"\n",
        "csv_path = EXAMPLES / \"data_ahu7.csv\"\n",
        "\n",
        "column_map = resolve_from_ttl(ttl_path)\n",
        "equipment_types = get_equipment_types_from_ttl(ttl_path)\n",
        "print(f\"Column map: {len(column_map)} mappings | Equipment: {equipment_types}\")\n",
        "\n",
        "all_rules = load_rules_from_dir(rules_dir)\n",
        "rules = _filter_rules_by_equipment(all_rules, equipment_types)\n",
        "print(f\"Rules: {len(rules)} apply to this equipment\")\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
        "df = _add_synthetic_columns(df, column_map)\n",
        "\n",
        "runner = RuleRunner(rules=rules)\n",
        "result = runner.run(df, timestamp_col=\"timestamp\", params={\"units\": \"imperial\"}, skip_missing_columns=True, column_map=column_map)\n",
        "\n",
        "flag_cols = [c for c in result.columns if c.endswith(\"_flag\")]\n",
        "print(f\"\\nFlag columns: {flag_cols}\")\n",
        "for col in flag_cols:\n",
        "    print(f\"  {col}: {int(result[col].sum())} fault samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Extract fault events (contiguous regions)\n",
        "\n",
        "Each fault flag is a boolean series. An *event* is a contiguous run of `True` values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_fault_events(df, flag_col):\n",
        "    \"\"\"Return list of (start_iloc, end_iloc, flag_name) for contiguous fault regions.\"\"\"\n",
        "    s = df[flag_col].astype(bool)\n",
        "    if not s.any():\n",
        "        return []\n",
        "    groups = (~s).cumsum()\n",
        "    fault_groups = groups[s]\n",
        "    events = []\n",
        "    for g in fault_groups.unique():\n",
        "        idx = fault_groups[fault_groups == g].index\n",
        "        pos = df.index.get_indexer(idx)\n",
        "        events.append((int(pos.min()), int(pos.max()), flag_col))\n",
        "    return events\n",
        "\n",
        "def all_fault_events(df, flag_cols):\n",
        "    \"\"\"Collect events from all flag columns.\"\"\"\n",
        "    events = []\n",
        "    for col in flag_cols:\n",
        "        events.extend(get_fault_events(df, col))\n",
        "    return sorted(events, key=lambda e: e[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "events = all_fault_events(result, flag_cols)\n",
        "print(f\"Total fault events: {len(events)}\")\n",
        "for col in flag_cols:\n",
        "    n = len([e for e in events if e[2] == col])\n",
        "    print(f\"  {col}: {n} events\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Zoom in on random fault events\n",
        "\n",
        "Pick random events and plot the time window around them. Signals + fault shading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Key signals to plot (Brick-mapped column names from TTL)\n",
        "SIGNAL_COLS = [\n",
        "    \"SAT (°F)\", \"MAT (°F)\", \"OAT (°F)\", \"RAT (°F)\",\n",
        "    \"SA Static Press (inH₂O)\", \"SF Spd Cmd (%)\", \"OA Damper Cmd (%)\",\n",
        "    \"Clg Vlv Cmd (%)\", \"Prht Vlv Cmd (%)\",\n",
        "]\n",
        "# Use whatever exists in result\n",
        "plot_cols = [c for c in SIGNAL_COLS if c in result.columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "def zoom_on_event(df, event, pad=24, signal_cols=None):\n",
        "    \"\"\"Plot signals in a window around a fault event. pad = samples before/after.\"\"\"\n",
        "    start_iloc, end_iloc, flag_name = event\n",
        "    center = (start_iloc + end_iloc) // 2\n",
        "    lo = max(0, center - pad)\n",
        "    hi = min(len(df) - 1, center + pad)\n",
        "    window = df.iloc[lo : hi + 1]\n",
        "    \n",
        "    if signal_cols is None:\n",
        "        signal_cols = [c for c in [\"SAT (°F)\", \"MAT (°F)\", \"OAT (°F)\", \"RAT (°F)\", \"SA Static Press (inH₂O)\", \"SF Spd Cmd (%)\", \"OA Damper Cmd (%)\"] if c in df.columns]\n",
        "    \n",
        "    n_axes = len(signal_cols) + 1  # +1 for fault flag\n",
        "    fig, axes = plt.subplots(n_axes, 1, figsize=(12, 2 * n_axes), sharex=True)\n",
        "    if n_axes == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    ts = window[\"timestamp\"] if \"timestamp\" in window.columns else window.index\n",
        "    \n",
        "    for ax, col in zip(axes[:-1], signal_cols):\n",
        "        if col in window.columns:\n",
        "            ax.plot(ts, window[col], color=\"#2e86ab\", linewidth=1.2)\n",
        "        ax.set_ylabel(col, fontsize=9)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.tick_params(axis=\"x\", labelsize=8)\n",
        "    \n",
        "    # Fault flag\n",
        "    flag_vals = window[flag_name] if flag_name in window.columns else pd.Series(0, index=window.index)\n",
        "    axes[-1].fill_between(ts, 0, flag_vals, color=\"#e94f37\", alpha=0.6, step=\"post\")\n",
        "    axes[-1].set_ylabel(flag_name, fontsize=9)\n",
        "    axes[-1].set_ylim(-0.1, 1.2)\n",
        "    axes[-1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Shade fault region on all axes (positions within window)\n",
        "    fault_lo = max(0, start_iloc - lo)\n",
        "    fault_hi = min(len(window) - 1, end_iloc - lo)\n",
        "    if fault_lo <= fault_hi:\n",
        "        for ax in axes[:-1]:\n",
        "            ax.axvspan(ts.iloc[fault_lo], ts.iloc[fault_hi], alpha=0.15, color=\"#e94f37\")\n",
        "    \n",
        "    fig.suptitle(f\"Zoom: {flag_name} @ iloc {start_iloc}-{end_iloc}\", fontsize=11)\n",
        "    plt.tight_layout()\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "n_sample = 3  # number of random events to plot\n",
        "sampled = random.sample(events, min(n_sample, len(events)))\n",
        "\n",
        "for event in sampled:\n",
        "    zoom_on_event(result, event, pad=48, signal_cols=plot_cols)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Event summary table\n",
        "\n",
        "Quick lookup: when did each fault type occur?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "event_rows = []\n",
        "for start_iloc, end_iloc, flag_name in events[:50]:  # first 50\n",
        "    t0 = result.iloc[start_iloc][\"timestamp\"] if \"timestamp\" in result.columns else start_iloc\n",
        "    t1 = result.iloc[end_iloc][\"timestamp\"] if \"timestamp\" in result.columns else end_iloc\n",
        "    duration = end_iloc - start_iloc + 1\n",
        "    event_rows.append({\"flag\": flag_name, \"start\": t0, \"end\": t1, \"duration_samples\": duration})\n",
        "\n",
        "pd.DataFrame(event_rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next: False positives\n",
        "\n",
        "Many fault flags can be **false positives** — the rule fired but the condition was acceptable (e.g. startup, setpoint change, sensor noise). The next tutorial covers:\n",
        "- Filtering by occupancy / schedule\n",
        "- Rolling-window confirmation\n",
        "- Manual review workflows\n",
        "- Tuning thresholds to reduce false positives"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
